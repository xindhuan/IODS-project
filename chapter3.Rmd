---
title: "chapter3"
author: "Xindi Huang"
date: "2023-11-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
date()

# laod packages
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
library(boot)
```

## Read alc dataset
```{r}
# set working directory
setwd("~/r/IODS/IODS-project/")

# read the joined student alcohol consumption data into R
alc <- read_csv("~/r/IODS/IODS-project/data/alc.csv",show_col_types=FALSE)

# print out the names of the variables
colnames(alc)
```

**Dataset information**:

This dataset  covers student achievement in secondary education for two Portuguese schools. Attributes include student grades `G1`, `G2`, `G3`, demographic factors `age`, `sex`, social features `family size`, `parental education`, etc., and school-related information `study time`,` support services`. Two distinct datasets are available for different subjects: Mathematics `mat` and Portuguese language `por`. `alc_use` is generated by averaging weekday and weekend alcohol consumption, and `high_use`, which is true if `alc_use` is greater than 2 and false otherwise.

## Hypothesis of relationships between high/low alcohol consumption and some of the other variables in the data. 

Here, I choose `studytime`, `health`, `age`, `failures` four variables, and my hypothesis are:

- *Hypothesis 1*: Students who spend more time studying (`studytime`) are likely to have lower alcohol consumption.

- *Hypothesis 2*: Students with better health status (`health`) may have lower alcohol consumption.

- *Hypothesis 3*: Older students tend to have higher alcohol consumption.

- *Hypothesis 4*: Students with a higher number of past class failures (`failures`) may have higher alcohol consumption.


## Numerically and graphically exploretion

**1. Study Time** (`studytime`):

```{r}

# 1. Study Time vs. Alcohol Consumption

alc %>%
  group_by(high_use) %>%
  summarise(count = n(),
            mean_studytime = mean(studytime))
```


```{r}
ggplot(alc, aes(x = high_use, y = studytime)) +
  geom_boxplot() + 
  ylab("studytime") + 
  ggtitle("Studytime by alchol consumption") + 
  theme_minimal()
```

- For students with high alcohol consumption, the average study time is lower, with a mean of 1.77. This suggests that, on average, students in this group spend less time studying. In contrast, for students with low alcohol consumption, the average study time is higher, with a mean of 2.16. This indicates that, on average, students in this group spend more time studying.

- The boxplot for `studytime` provides evidence that students with low alcohol consumption tend to spend more time studying compared to students with high alcohol consumption. This observation is consistent with the hypothesis that higher study time is associated with lower alcohol consumption.

**2. Health Status** (`health`):

```{r}
# 2. Health Status vs. Alcohol Consumption
alc %>%
  group_by(high_use) %>%
  summarise(count = n(),
            mean_health = mean(health))
```

```{r}
ggplot(alc, aes(x = high_use, y = health)) +
  geom_boxplot() + 
  ylab("Health Status")
  ggtitle("Health Status by Alchol consumption") +
  theme_minimal()
```

- Interetsingly, the distribution of health status suggests a subtle difference between students with high and low alcohol consumption. Students with high alcohol consumption tend to report a slightly higher average health status  compared to those with low alcohol consumption.

- The boxplot for `health` does not show a substantial difference between the health statuses of students with high alcohol consumption  and low alcohol consumption . This observation does not strongly support the hypothesis that students with better health status are associated with lower alcohol consumption in this dataset.

**3. Age** (`age`):
```{r}
# 3. Age vs. Alcohol Consumption
alc %>%
  group_by(high_use) %>%
  summarise(count = n(),
            mean_age = mean(age))
```

```{r}
ggplot(alc, aes(x = high_use, y = age)) +
  geom_boxplot() + 
  ylab("Age")
  ggtitle("Age by Alchol consumption") +
  theme_minimal()
```

- The distribution of age suggests a small difference between students with high and low alcohol consumption. Students with high alcohol consumption tend to be slightly older on average compared to those with low alcohol consumption.

- The boxplot for `age` provides evidence that younger students tend to have lower alchol consumption. This observation is consistent with the hypothesis that older students tend to have higher alcohol consumption.

**4. Number of past class failures **(`failures`):
```{r}
# 4. Number of past class failures vs. Alcohol Consumption
alc %>%
  group_by(high_use) %>%
  summarise(count = n(),
            mean_failures = mean(failures))
```

```{r}
ggplot(alc, aes(x = high_use, y = failures)) +
  geom_boxplot() + 
  ylab("Number of past class failures")
  ggtitle("Failures by Alchol consumption") +
  theme_minimal()
```

- The distribution of the number of past class failures suggests a difference between students with high and low alcohol consumption. Students with high alcohol consumption tend to have a higher average number of past class failures compared to those with low alcohol consumption.

- But there may not be a clear distinction in the number of past class failures between students with high and low alcohol consumption from the boxplot .

## Logistic regression model

```{r}
# Fit logistic regression model
lr_mod <- glm(high_use ~ studytime + health + age + failures, data = alc, family = "binomial")

# Summarize the model
summary(lr_mod)
```

**Coefficients**

- `Intercept`: The intercept is -3.075. It represents the log-odds of high alcohol consumption when all predictor variables are zero.

- `studytime`: For each one-unit decrease in study time, the log-odds of high alcohol consumption decrease by 0.547. The variable is statistically significant.

- `health`: The log-odds of high alcohol consumption increase by 0.094 for each one-unit increase in health. However, this variable is not statistically significant.

- `age`: For each one-unit increase in age, the log-odds of high alcohol consumption increase by 0.172. This variable is marginally significant.

- `failures`: For each one-unit increase in failures, the log-odds of high alcohol consumption increase by 0.442. This variable is statistically significant.

Overall, the model suggests that `studytime` and `failures` are significant predictors of high alcohol consumption.


```{r}
# Extract odds ratios and confidence intervals
OR <- exp(coef(lr_mod))
CI <- exp(confint(lr_mod))

# print out the odds ratios with their confidence intervals
cbind(OR, CI)

```

The odds ratios (`OR`) and their 95% confidence intervals (`CI`) provide additional information about the relationship between the predictor variables and the odds of high alcohol consumption:

- `Intercept`: The odds of high alcohol consumption for the reference group are 0.0462. The CI ranges from 0.00135 to 1.474, and it includes 1. This suggests that the odds of high alcohol consumption for the reference group are not significantly different from 1.

- `studytime`: The odds ratio is 0.5787, with a 95% CI ranging from 0.4196 to 0.7838. This indicates that, holding other variables constant, a one-unit decrease in study time is associated with a 42.13% decrease in the odds of high alcohol consumption.

- `health`: The odds ratio is 1.0991, with a CI ranging from 0.9302 to 1.3041, suggesting that there is no significant association between health status and the odds of high alcohol consumption.

- `age`: OR is 1.188, with a CI ranging from 0.9712 to 1.4591, indicating that there is no significant association between age and the odds of high alcohol consumption.

- `failures`: OR is 1.5565, with a CI ranging from 1.0386 to 2.3726. This suggests that, holding other variables constant, a one-unit increase in failures is associated with a 55.65% increase in the odds of high alcohol consumption.

In summary, the odds ratios provide insights into the direction and magnitude of the relationships between each predictor and the odds of high alcohol consumption. Interpretation of the results involves considering both the point estimates and the confidence intervals. The significant predictors in this model are `studytime` and `failures`, which support *hypothesis 1* and *hypothesis 4*.

## Predictive power of the model

```{r}
# Fit logistic regression model
lr_mod <- glm(high_use ~ studytime + health + age + failures, data = alc, family = "binomial")

# predict() the probability of high_use
probabilities <- predict(lr_mod, type = "response")

# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = probability > 0.5)

# see the last ten original classes, predicted probabilities, and class predictions
select(alc, studytime, health, age, failures, high_use, probability, prediction) %>% tail(10)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)

```


- True Positives (TP): 33
- True Negatives (TN): 252
- False Positives (FP): 7
- False Negatives (FN): 78


```{r}
# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = 0)

# change the prob argument to 1
loss_func(class = alc$high_use, prob = 1)

# change the prob argument to prediction probabilities in alc
loss_func(class = alc$high_use, prob = alc$probability)
```
- The loss is 0.2297, indicating that the logistic regression model's predictions have an average error rate of approximately 23%.

In summary, the model shows decent accuracy.


## 10-fold cross-validation

```{r}
# compute the average number of wrong predictions in the (training) data
train_error <- loss_func(class = alc$high_use, prob = alc$probability)

# K-fold cross-validation
cv <- cv.glm(data = alc, cost = loss_func, glmfit = lr_mod, K = nrow(alc))

# average number of wrong predictions in the cross validation
cv$delta[1]

# 10-fold cross-validation
cv_10fold <- cv.glm(data = alc, cost = loss_func, glmfit = lr_mod, K = 10)
cv_10fold$delta[1]

```

Compared to the model introduced in the Exercise Set (which had about 0.26 error), it seems that my logistic regression model has a slightly higher prediction error. 

